{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SrQeW6kEURFh",
        "outputId": "ee6c4e61-fac6-4379-fec2-3f66091baa08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- INTERVIEW APPROACH ---\n",
            "Great! I'm excited to help you brainstorm for your travel blog. Before we dive in, let's get a feel for what you're planning.\n",
            "\n",
            "Here are 3 questions:\n",
            "\n",
            "1. **Where are you planning to travel to (or where did you *recently* travel to that you want to blog about)?** Be as specific as possible - city, region, country!\n",
            "2. **What's the *vibe* you're going for with your blog?** (e.g., budget backpacking, luxury travel, adventure focused, food-centric, family travel, slow travel, solo female travel, etc.)\n",
            "3. **Who is your ideal reader?** (e.g., other budget backpackers, families with young children, luxury travelers, people interested in sustainable tourism, etc.)\n",
            "\n",
            "\n",
            "\n",
            "Let me know your answers and we'll go from there! ✨\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--- CHAIN OF THOUGHT (COT) ---\n",
            "Here's how to solve this problem:\n",
            "\n",
            "* **Understanding the key:** The problem states it takes 2 hours to dry *one* shirt.\n",
            "* **Assuming enough space:** We assume there's enough space outside to hang all 5 shirts so they each get airflow.\n",
            "* **Shirts dry independently:** Each shirt dries at the same rate as any other shirt.\n",
            "\n",
            "Therefore, it will still take **2 hours** to dry 5 shirts. They all dry simultaneously!\n",
            "\n",
            "\n",
            "--- TREE OF THOUGHTS (TOT) ---\n",
            "Okay, here's a summary of the consensus between Expert 1 (Logic) and Expert 2 (Creative) regarding whether AI will replace artists, based on a typical discussion dynamic between those two perspectives. This is a synthesis of common arguments, as I don't have a specific transcript to work from.\n",
            "\n",
            "**The Consensus: AI won't *replace* artists, but it will fundamentally *change* the role of the artist and the art landscape.**\n",
            "\n",
            "Here's a breakdown of how they likely arrived at that conclusion:\n",
            "\n",
            "* **Expert 1 (Logic) acknowledged AI's rapid progress:**  They pointed out AI's ability to mimic styles, generate technically proficient images/music/writing, and automate tedious tasks.  Logically, this *could* displace artists doing very repetitive, skill-based work (e.g., stock image creation, basic graphic design). They also highlighted the economic pressures that might lead businesses to favor cheaper AI-generated content.\n",
            "* **Expert 2 (Creative) emphasized the core of art is *not* just technical skill:** They argued that art is fundamentally about human expression, emotional resonance, conceptual thinking, storytelling, and communicating unique perspectives. AI, while capable of *simulating* these things, doesn't *experience* them.  It lacks genuine intent, lived experience, and the ability to truly innovate beyond its training data.\n",
            "* **Where they met in the middle:** Both agreed that AI is a *tool*.  A powerful tool, but a tool nonetheless. \n",
            "    * **AI as a collaborator:**  They envisioned artists using AI to augment their abilities – for brainstorming, prototyping, automating repetitive tasks, exploring new styles, and overcoming technical limitations.  It can be a powerful assistant.\n",
            "    * **The value shift:** The value will shift *from* purely technical execution *to* the artist's ability to curate, direct, conceptualize, and imbue work with meaning.  The \"prompt engineer\" or \"AI art director\" could become a significant role.\n",
            "    * **New art forms:** AI will likely *enable* entirely new art forms that we can't currently imagine, requiring artists to adapt and explore these possibilities.\n",
            "    * **Authenticity & Human Connection:**  In a world flooded with AI-generated content, *authenticity* and the demonstrable human touch will become even *more* valuable and sought after.  People will still crave art that feels genuinely human.\n",
            "\n",
            "**In essence, their consensus is not about extinction, but about evolution.**  AI won't eliminate the *need* for artists, but it will change *what* artists do and *how* they do it.  The artists who thrive will be those who embrace AI as a tool and focus on the uniquely human aspects of their craft – the conceptual, emotional, and storytelling elements that AI cannot replicate.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--- ZERO-SHOT ---\n",
            "Dreaming, theorizing, struggling, learning, booming, now transforming everything.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--- FEW-SHOT ---\n",
            "Model Error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "\n",
        "# 1. Configuration\n",
        "genai.configure(api_key=\"  \") # YOUR KEY\n",
        "\n",
        "# Switch to Gemma 3 - it often bypasses the strict Gemini 'Billing-Only' quota\n",
        "SELECTED_MODEL = \"models/gemma-3-27b-it\"\n",
        "\n",
        "def get_gemini_response(prompt):\n",
        "    model = genai.GenerativeModel(SELECTED_MODEL)\n",
        "    try:\n",
        "        # Gemma models require slightly simpler settings\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Model Error: {e}\"\n",
        "\n",
        "# 2. The Implementation tasks\n",
        "tasks = {\n",
        "    \"Interview Approach\": \"I want to write a travel blog. Before you start, ask me 3 questions about my destination and style.\",\n",
        "    \"Chain of Thought (CoT)\": \"If it takes 2 hours to dry 1 shirt, how long does it take to dry 5 shirts outside? Think step-by-step.\",\n",
        "    \"Tree of Thoughts (ToT)\": \"Expert 1 (Logic) and Expert 2 (Creative) discuss if AI will replace artists. Summarize their consensus.\",\n",
        "    \"Zero-Shot\": \"Summarize the history of AI in 10 words.\",\n",
        "    \"Few-Shot\": \"Review: 'Great' -> Sentiment: Pos\\nReview: 'Bad' -> Sentiment: Neg\\nReview: 'It was okay' -> Sentiment:\"\n",
        "}\n",
        "\n",
        "# 3. Running the Assignment\n",
        "for name, prompt in tasks.items():\n",
        "    print(f\"\\n--- {name.upper()} ---\")\n",
        "    result = get_gemini_response(prompt)\n",
        "    print(result)\n",
        "    time.sleep(1) # Small delay for safety"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E97p5gcymT8Q"
      },
      "source": [
        "Zero Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "U7MLExbUoe0v",
        "outputId": "c95c4018-9851-42ea-e9e1-4cb8781da41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- ZERO SHOT ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemma-3-27b-it:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 606.93ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**Neutral**\n",
            "\n",
            "**Reasoning:**\n",
            "\n",
            "The sentence contains both a negative aspect (\"food was cold\") and a positive aspect (\"view was great\"). These opposing sentiments balance each other out, resulting in an overall neutral sentiment. It's not overwhelmingly positive or negative.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "zero_shot = \"Classify sentiment: 'The food was cold but the view was great.' Options: Positive, Negative, Neutral.\"\n",
        "\n",
        "print(\"--- ZERO SHOT ---\")\n",
        "print(get_gemini_response(zero_shot))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di5Xm5QMmc-v"
      },
      "source": [
        "Few Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "MfoOeLWlo5SW",
        "outputId": "e5b168d0-cf50-4a8c-9813-781be9149703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- FEW SHOT ---\n",
            "Review: 'The food was cold but the view was great.' | Sentiment: **Mixed** \n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "This review contains both positive (\"view was great\") and negative (\"food was cold\") elements. Therefore, it doesn't fall neatly into purely positive or negative, and is best categorized as mixed.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "few_shot = \"\"\"\n",
        "Review: 'Best phone ever!' | Sentiment: Positive\n",
        "Review: 'It's okay.' | Sentiment: Neutral\n",
        "Review: 'The food was cold but the view was great.' | Sentiment:\"\"\"\n",
        "\n",
        "print(\"\\n--- FEW SHOT ---\")\n",
        "print(get_gemini_response(few_shot))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81avmJAlmfhX"
      },
      "source": [
        "Chain of Thought (CoT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "1qPgMnNqmYaA",
        "outputId": "c1890ed0-d4b2-49c7-bd16-06b2458d0738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- CHAIN OF THOUGHT ---\n",
            "Here's how to solve this step-by-step:\n",
            "\n",
            "* **Sally is a sister:** We know Sally is one of the sisters.\n",
            "* **Brothers share sisters:** All the brothers share the same sisters.\n",
            "* **Two sisters total:** Since each brother has 2 sisters, and Sally is one of them, there must be one other sister.\n",
            "\n",
            "**Answer:** Sally has 1 sister.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. Chain of Thought (CoT)\n",
        "cot = \"Sally has 3 brothers. Each brother has 2 sisters. How many sisters does Sally have? Let's think step-by-step.\"\n",
        "\n",
        "print(\"\\n--- CHAIN OF THOUGHT ---\")\n",
        "print(get_gemini_response(cot))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5jCXyMKmprG"
      },
      "source": [
        "Interview-Style Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "nd_5PSNBmZf_",
        "outputId": "5f342cfc-0862-4e9d-d416-e4d442c683c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- INTERVIEW ---\n",
            "Okay, great! Let's get a better understanding of who you're building this app *for*. I'll ask you three questions. Answer as thoroughly as you can - the more detail, the better the suggestions I can give you.\n",
            "\n",
            "Here's the first question:\n",
            "\n",
            "**1. Imagine your ideal user. Describe them - not just demographics like age and gender, but also their current fitness level, their motivations for wanting to get fitter, and what struggles they currently face when trying to achieve their fitness goals.** \n",
            "\n",
            "Take your time and really paint a picture of this person.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Interview\n",
        "interview = \"I want to build a fitness app. Interview me with 3 questions to understand my target audience before suggesting features.\"\n",
        "\n",
        "print(\"\\n--- INTERVIEW ---\")\n",
        "print(get_gemini_response(interview))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvJvDR7cmj4Q"
      },
      "source": [
        "Tree of Thought (ToT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "8gLceUHWmnpn",
        "outputId": "3cc05904-9870-43b9-f394-ed5c43aef775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- TREE OF THOUGHTS ---\n",
            "## The Cat Corner Riddle - Expert Discussion\n",
            "\n",
            "**The Riddle:** A room has 4 corners. A cat sits in each corner. In front of each cat are 3 cats. How many cats are there?\n",
            "\n",
            "**Expert 1: The Geometer (Dr. Anya Sharma)**\n",
            "\n",
            "“Right, let’s start with the spatial arrangement. We have a room, presumably rectangular or square, with four corners. A cat is positioned at each corner. This establishes a clear, fixed number of cats – four. Now, the statement ‘in front of each cat are 3 cats’ is where it gets interesting.  From a purely geometric perspective, ‘in front’ implies a direction.  If we assume the cats are facing inwards towards the center of the room, then each cat *can* see three others.  It’s a symmetrical arrangement.  However, geometry alone doesn’t tell us if these are *distinct* cats. It just confirms the possibility of the visual arrangement.”\n",
            "\n",
            "**Expert 2: The Linguist (Professor Ben Carter)**\n",
            "\n",
            "“Anya’s geometric analysis is sound, but we *must* dissect the wording. The phrase ‘in front of’ is key. It doesn’t say ‘there *are* 3 cats in front of’, it says ‘in front of each cat *are* 3 cats’. This is a subtle but crucial distinction. It implies a relationship, a perspective.  The wording doesn’t necessitate additional cats beyond the initial four.  It’s describing what each cat *perceives*, not a statement of total quantity.  Think about it – if there were more than four cats, the statement wouldn’t hold true for *every* cat. Some cats would have fewer than three in front of them. The use of ‘are’ instead of ‘there are’ is a classic riddle trick, shifting focus from quantity to relationship.”\n",
            "\n",
            "**Expert 3: The Synthesizer (Ms. Chloe Dubois)**\n",
            "\n",
            "“Okay, I’m listening. Anya establishes the minimum of four cats based on the corners. Ben highlights the deceptive nature of the wording, suggesting the ‘3 cats in front’ is a perceptual statement, not an additive one.  If we accept Ben’s linguistic analysis, and the wording is designed to mislead us into thinking we need to *add* cats, then the answer isn’t about finding more cats. It’s about recognizing that the four cats already present fulfill the condition. Each cat *sees* three others, but they are the same four cats being counted from different viewpoints.  The riddle is playing on our tendency to interpret ‘in front of’ as requiring additional entities.”\n",
            "\n",
            "**(A pause as Chloe considers)**\n",
            "\n",
            "“Let’s test it. Cat A sees Cats B, C, and D. Cat B sees Cats A, C, and D. Cat C sees Cats A, B, and D. Cat D sees Cats A, B, and C. The condition is met with only four cats.”\n",
            "\n",
            "\n",
            "\n",
            "**Final Answer (Chloe Dubois):**\n",
            "\n",
            "“Therefore, the answer is **four** cats. The riddle is a trick of perspective and wording, designed to make you believe there are more cats than there actually are.”\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tot = \"\"\"\n",
        "Three experts are solving a riddle: 'A room has 4 corners. A cat sits in each corner.\n",
        "In front of each cat are 3 cats.'\n",
        "Expert 1: Analyzes the geometry.\n",
        "Expert 2: Analyzes the wording.\n",
        "Expert 3: Synthesizes the final count.\n",
        "Show their discussion and final answer.\"\"\"\n",
        "\n",
        "print(\"\\n--- TREE OF THOUGHTS ---\")\n",
        "print(get_gemini_response(tot))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
